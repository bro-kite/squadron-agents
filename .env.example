# Squadron Agent Framework - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Provider: openai, anthropic, ollama, huggingface, openai_compatible
LLM_PROVIDER=openai

# Model name (depends on provider)
LLM_MODEL=gpt-4o

# Generation settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# =============================================================================
# API Keys
# =============================================================================

# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Hugging Face
HF_TOKEN=hf_...

# =============================================================================
# Custom Endpoints
# =============================================================================

# For OpenAI-compatible APIs (vLLM, DigitalOcean GPU, RunPod, Together AI, etc.)
# LLM_BASE_URL=https://your-gpu-server.com/v1

# Ollama (local models)
LLM_OLLAMA_BASE_URL=http://localhost:11434

# Run Hugging Face models locally
LLM_USE_LOCAL_MODEL=false

# =============================================================================
# Memory (Neo4j / Graphiti)
# =============================================================================

# Leave empty to use in-memory storage
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# =============================================================================
# Research Tools
# =============================================================================

# Serper API for web search
SERPER_API_KEY=

# Tavily API (alternative)
TAVILY_API_KEY=

# =============================================================================
# Reasoning Configuration
# =============================================================================

# LATS / MCTS settings
REASONING_N_CANDIDATES=5
REASONING_MAX_DEPTH=10
REASONING_EXPLORATION_CONSTANT=1.41

# =============================================================================
# Governance
# =============================================================================

# Enable safety guardrails
GOVERNANCE_ENABLE_GUARDRAILS=true

# Maximum iterations per agent run
GOVERNANCE_MAX_ITERATIONS=50

# =============================================================================
# Evolution (SICA)
# =============================================================================

# Enable self-improvement (use with caution)
EVOLUTION_ENABLE_SELF_IMPROVEMENT=false

# Minimum improvement threshold to accept mutations
EVOLUTION_MIN_IMPROVEMENT=0.05

# Sandbox type: subprocess, docker
EVOLUTION_SANDBOX_TYPE=subprocess
